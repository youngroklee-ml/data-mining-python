# Classification

```{python}
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
```

## Example 5.2

### Load data

```{python}
dat1 = pd.read_csv("data/ch7_dat1.csv")
dat1
```

```{python}
X = dat1[['X1', 'X2']]
y = LabelBinarizer().fit_transform(dat1['class'])
```


### Training and testing data

Let us use the first 7 observations as training data, while remaining 2 observations as testing data.

```{python}
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=2, train_size=7, 
    random_state=None, shuffle=False
)
```


### k-nearest neighbors classifier

Use `KNeighborsClassifier()` from `sklearn.neighbors` module to define a kNN model for a classification problem.

Set `n_neighbors=3` to train 3-NN in this example.

```{python}
knn_model = KNeighborsClassifier(n_neighbors=3)
```

Train the 3-NN classifier on training data.

```{python}
knn_model.fit(X_train, y_train)
```

Use `predict()` method to make a prediction on training data.

```{python}
pd.DataFrame(X_train).assign(
    observed_class = y_train,
    pred_class = knn_model.predict(X_train)
)
```

Also, maka a prediction on testing data.

```{python}
pd.DataFrame(X_test).assign(
    observed_class = y_test,
    pred_class = knn_model.predict(X_test)
)
```
